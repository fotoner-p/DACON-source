{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Classification-of-novel-writers.ipynb","provenance":[],"collapsed_sections":["-tDagOp5luBE","2Hp-Yyh-l-mt","f_tc64LNucEq"],"mount_file_id":"1-UHKb_Dxxc5g8HCFoRsRHrEVXhW_pilY","authorship_tag":"ABX9TyPZQODfc/EHSOumcO94Dk/z"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RswEYL504Y26","executionInfo":{"status":"ok","timestamp":1607048596093,"user_tz":-540,"elapsed":6960,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"37d9ab2d-c446-46e6-d8bf-86654cbe53d9"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import re\n","import seaborn as sns\n","\n","import os\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","from nltk.tag import pos_tag\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","os.chdir('/content/drive/My Drive/dacon_/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LBcByDQe4bRp"},"source":["def alpha_num(text):\n","    return re.sub(r'[^A-Za-z0-9/]', ' ', text)\n","\n","def tokenize(text):\n","    return \" \".join([item[0] + \"/\" + item[1] for item in pos_tag(word_tokenize(text))])\n","\n","# def tokenize(text):\n","#     return \" \".join(word_tokenize(text))\n","\n","def remove_stopwords(text):\n","    final_text = []\n","    for i in text.split():\n","        if i.strip().lower() not in stopwords:\n","            final_text.append(i.strip())\n","    return \" \".join(final_text)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UIow-Zi4c4m"},"source":["df = pd.read_csv('train.csv')\n","#df['text'] = df['text'].str.lower().apply(alpha_num)\n","df['text'] = df['text'].str.lower().apply(alpha_num).apply(tokenize)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"4o1NZP0pizOH","executionInfo":{"status":"ok","timestamp":1607058816085,"user_tz":-540,"elapsed":710,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"3d9f9b1f-1c9b-40ee-a40a-5bd2a7a56a96"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>he/PRP was/VBD almost/RB choking/VBG there/EX ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>your/PRP$ sister/NN asked/VBD for/IN it/PRP i/...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>she/PRP was/VBD engaged/VBN one/CD day/NN as/I...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>the/DT captain/NN was/VBD in/IN the/DT porch/N...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>have/VB mercy/VBN gentlemen/NNS odin/RB flung/...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                                               text  author\n","0      0  he/PRP was/VBD almost/RB choking/VBG there/EX ...       3\n","1      1  your/PRP$ sister/NN asked/VBD for/IN it/PRP i/...       2\n","2      2  she/PRP was/VBD engaged/VBN one/CD day/NN as/I...       1\n","3      3  the/DT captain/NN was/VBD in/IN the/DT porch/N...       4\n","4      4  have/VB mercy/VBN gentlemen/NNS odin/RB flung/...       3"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"id":"uduUHkC_5Ukb"},"source":["vocab_size = 40000\n","tokenizer = Tokenizer(vocab_size)\n","tokenizer.fit_on_texts(df['text'])\n","sequences = tokenizer.texts_to_sequences(df['text'])\n","\n","max_len = 300\n","\n","x_train = pad_sequences(sequences, maxlen=max_len)\n","y_train = df['author'].to_numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2Ed9G_MlhWw"},"source":["# 모델 1 (simple Conv1D )"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ik5wNUyt5WlX","executionInfo":{"status":"ok","timestamp":1607058830126,"user_tz":-540,"elapsed":684,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"2d9cd956-9e43-44c5-83c2-16421f078362"},"source":["# val_loss: 0.7529\n","# val_loss: 0.8304 Not import NLTK \n","embedding_size = 100\n","filter = 64\n","\n","\n","model = keras.models.Sequential([\n","    keras.layers.Embedding(vocab_size, embedding_size, input_shape=(max_len,)),\n","    keras.layers.Conv1D(filter, 3, padding=\"same\", activation=\"relu\"),\n","    keras.layers.GlobalMaxPooling1D(),\n","    keras.layers.Dropout(.3),\n","    keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2()),\n","    keras.layers.Dense(5, activation=\"softmax\"),\n","])\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['acc'])\n","model.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_31 (Embedding)     (None, 300, 100)          4000000   \n","_________________________________________________________________\n","conv1d_71 (Conv1D)           (None, 300, 64)           19264     \n","_________________________________________________________________\n","global_max_pooling1d_49 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_40 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_38 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 5)                 165       \n","=================================================================\n","Total params: 4,021,509\n","Trainable params: 4,021,509\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-tDagOp5luBE"},"source":["# 모델 2 (Bidirectional LSTM)"]},{"cell_type":"code","metadata":{"id":"FkeyvGKS9z5z"},"source":["embedding_size = 32\n","filter = 64\n","\n","x_input = keras.Input((max_len,))\n","embedding = keras.layers.Embedding(vocab_size, embedding_size)(x_input)\n","do1 = keras.layers.SpatialDropout1D(.5)(embedding)\n","\n","lstm1 = keras.layers.Bidirectional(keras.layers.LSTM(filter, return_sequences=True))(do1)\n","lstm2 = keras.layers.Bidirectional(keras.layers.LSTM(filter, return_sequences=True))(lstm1)\n","\n","hidden = keras.layers.Concatenate()([\n","    keras.layers.GlobalMaxPooling1D()(lstm2),\n","    keras.layers.GlobalAveragePooling1D()(lstm2),\n","])\n","d1 = keras.layers.Dense(filter * 2)(hidden)\n","do3 = keras.layers.Dropout(.3)(d1)\n","d2 = keras.layers.Dense(filter * 2)(do3)\n","do4 = keras.layers.Dropout(.3)(d2)\n","output = keras.layers.Dense(5, activation='sigmoid')(do4)\n","\n","model = keras.models.Model(x_input, output)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['acc'])\n","model.summary()\n","# keras.utils.plot_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1XU7OrAYl2rB"},"source":["# 모델3 (Multi Conv1D)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LxxMK4M2c1zJ","executionInfo":{"status":"ok","timestamp":1607059125787,"user_tz":-540,"elapsed":665,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"2fb1fb63-1565-498a-eaa0-3897dee2e425"},"source":["# [3, 6, 12]\n","# val_loss: 0.5843 (filter: 64, embedding_size: 64)\n","# val_loss: 0.5753 (filter: 128, embedding_size: 64)\n","\n","# val_loss: 0.5721 (filter: 128, embedding_size: 32)\n","# val_loss: 0.6686 (filter: 128, embedding_size: 32) Not import NLTK \n","\n","# val_loss: 0.6149  (filter: 128, embedding_size: 16) 마지막 에폭까지 수렴이 안 됨\n","# val_loss: 0.5974  (filter: 256, embedding_size: 32) \n","\n","# [3, 6, 9]\n","\n","embedding_size = 32\n","filter = 128\n","\n","def multi_kernel(filter_size, input_layer):\n","    kernel_size = [3, 6, 12]\n","    conv_blocks = []\n","\n","    for ks in kernel_size:\n","        conv = keras.layers.Conv1D(filter_size, ks, padding=\"valid\", activation=\"relu\")(input_layer)\n","        max_pool = keras.layers.GlobalMaxPooling1D()(conv)\n","        conv_blocks.append(max_pool)\n","\n","    return conv_blocks\n","\n","x_input = keras.Input((max_len,))\n","embedding = keras.layers.Embedding(vocab_size, embedding_size)(x_input)\n","do1 = keras.layers.Dropout(.3)(embedding)\n","convs = multi_kernel(filter, do1)\n","\n","concatenate = keras.layers.Concatenate()(convs)\n","do2 = keras.layers.Dropout(.3)(concatenate)\n","d1 = keras.layers.Dense(filter, activation='relu')(do2)\n","do3 = keras.layers.Dropout(.3)(d1)\n","output = keras.layers.Dense(5, activation='sigmoid')(do3)\n","\n","model = keras.models.Model(x_input, output)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['acc'])\n","model.summary()\n","# keras.utils.plot_model(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_29\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_19 (InputLayer)           [(None, 300)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_35 (Embedding)        (None, 300, 32)      1280000     input_19[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 300, 32)      0           embedding_35[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_81 (Conv1D)              (None, 298, 128)     12416       dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","conv1d_82 (Conv1D)              (None, 295, 128)     24704       dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","conv1d_83 (Conv1D)              (None, 289, 128)     49280       dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","global_max_pooling1d_59 (Global (None, 128)          0           conv1d_81[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_60 (Global (None, 128)          0           conv1d_82[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_61 (Global (None, 128)          0           conv1d_83[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 384)          0           global_max_pooling1d_59[0][0]    \n","                                                                 global_max_pooling1d_60[0][0]    \n","                                                                 global_max_pooling1d_61[0][0]    \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 384)          0           concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","dense_44 (Dense)                (None, 128)          49280       dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 128)          0           dense_44[0][0]                   \n","__________________________________________________________________________________________________\n","dense_45 (Dense)                (None, 5)            645         dropout_49[0][0]                 \n","==================================================================================================\n","Total params: 1,416,325\n","Trainable params: 1,416,325\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2Hp-Yyh-l-mt"},"source":["# 모델4 (Multi Conv1D stack)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"autNZ-cxBCFD","executionInfo":{"status":"ok","timestamp":1607059336544,"user_tz":-540,"elapsed":741,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"362257d1-2d54-49d9-fcb0-947119837aad"},"source":["# [3, 6, 12]\n","# val_loss: 0.5843 (filter: 64, embedding_size: 64)\n","# val_loss: 0.5753 (filter: 128, embedding_size: 64)\n","\n","# val_loss: 0.5721 (filter: 128, embedding_size: 32)\n","# val_loss: 0.6686 (filter: 128, embedding_size: 32) Not import NLTK \n","\n","# val_loss: 0.6149  (filter: 128, embedding_size: 16) 마지막 에폭까지 수렴이 안 됨\n","# val_loss: 0.5974  (filter: 256, embedding_size: 32) \n","\n","# [3, 6, 9]\n","\n","embedding_size = 64\n","filter = 128\n","\n","def multi_kernel(filter_size, input_layer):\n","    kernel_size = [3, 6, 12]\n","    conv_blocks = []\n","\n","    for ks in kernel_size:\n","        conv1 = keras.layers.Conv1D(filter_size, ks, padding=\"same\", activation=\"relu\")(input_layer)\n","        pool1 = keras.layers.MaxPool1D()(conv1)\n","        conv2 = keras.layers.Conv1D(filter_size, ks, padding=\"same\", activation=\"relu\")(pool1)\n","        global_pool = keras.layers.GlobalMaxPool1D()(conv2)\n","\n","        conv_blocks.append(global_pool)\n","\n","    return conv_blocks\n","\n","x_input = keras.Input((max_len,))\n","embedding = keras.layers.Embedding(vocab_size, embedding_size, trainable=True)(x_input)\n","convs = multi_kernel(filter, embedding)\n","\n","concatenate = keras.layers.Concatenate()(convs)\n","do2 = keras.layers.Dropout(.3)(concatenate)\n","d1 = keras.layers.Dense(64, activation='relu')(do2)\n","output = keras.layers.Dense(5, activation='softmax')(d1)\n","\n","model = keras.models.Model(x_input, output)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['acc'])\n","model.summary()\n","# keras.utils.plot_model(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_33\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_21 (InputLayer)           [(None, 300)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_37 (Embedding)        (None, 300, 64)      2560000     input_21[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_90 (Conv1D)              (None, 300, 128)     24704       embedding_37[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_92 (Conv1D)              (None, 300, 128)     49280       embedding_37[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_94 (Conv1D)              (None, 300, 128)     98432       embedding_37[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling1d_22 (MaxPooling1D) (None, 150, 128)     0           conv1d_90[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling1d_23 (MaxPooling1D) (None, 150, 128)     0           conv1d_92[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling1d_24 (MaxPooling1D) (None, 150, 128)     0           conv1d_94[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_91 (Conv1D)              (None, 150, 128)     49280       max_pooling1d_22[0][0]           \n","__________________________________________________________________________________________________\n","conv1d_93 (Conv1D)              (None, 150, 128)     98432       max_pooling1d_23[0][0]           \n","__________________________________________________________________________________________________\n","conv1d_95 (Conv1D)              (None, 150, 128)     196736      max_pooling1d_24[0][0]           \n","__________________________________________________________________________________________________\n","global_max_pooling1d_65 (Global (None, 128)          0           conv1d_91[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_66 (Global (None, 128)          0           conv1d_93[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_67 (Global (None, 128)          0           conv1d_95[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 384)          0           global_max_pooling1d_65[0][0]    \n","                                                                 global_max_pooling1d_66[0][0]    \n","                                                                 global_max_pooling1d_67[0][0]    \n","__________________________________________________________________________________________________\n","dropout_51 (Dropout)            (None, 384)          0           concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","dense_48 (Dense)                (None, 64)           24640       dropout_51[0][0]                 \n","__________________________________________________________________________________________________\n","dense_49 (Dense)                (None, 5)            325         dense_48[0][0]                   \n","==================================================================================================\n","Total params: 3,101,829\n","Trainable params: 3,101,829\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f_tc64LNucEq"},"source":["# 모델 5 (ELMo  임베딩)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50TvY5IK3Sq0","executionInfo":{"status":"ok","timestamp":1607048385326,"user_tz":-540,"elapsed":29279,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"8c82b361-8f4c-4ed1-ed7c-52ecb8d1443e"},"source":["!pip install tensorflow_text\n","import tensorflow_text\n","import tensorflow_hub as hub\n","\n","bert_preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\")\n","bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\",trainable=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.6/dist-packages (2.3.0)\n","Requirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text) (2.3.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (2.3.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (2.10.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (0.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (3.3.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (0.35.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (3.12.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.33.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.12.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.15.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.1.0)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.4.1)\n","Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (1.18.5)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow_text) (0.3.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (3.3.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (50.3.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (2.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (2.10)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow_text) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQ9Y5jqvZaFx","outputId":"d2e9573d-7cda-490f-e826-cae7001d8693"},"source":["df = pd.read_csv('train.csv')\n","#df['text'] = df['text'].str.lower().apply(alpha_num)\n","x_train = df['text'].to_numpy()\n","y_train = df['author'].to_numpy()\n","\n","text_input = keras.layers.Input(shape=(), dtype=tf.string)\n","encoder_inputs = bert_preprocessor(text_input)\n","bert_output = bert_encoder(encoder_inputs)[\"sequence_output\"]\n","\n","bert_transformation = keras.models.Model(text_input, bert_output)\n","x_train = bert_transformation.predict(x_train, batch_size=256, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["215/215 [==============================] - 70s 326ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYA0N-3zubXx","executionInfo":{"status":"ok","timestamp":1607048149832,"user_tz":-540,"elapsed":671,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"a08267eb-5560-44df-f6dc-570865d9eba7"},"source":["max_len = 128\n","\n","x_input = keras.Input((max_len,))\n","d1 = keras.layers.Dense(max_len // 2, activation='relu')(x_input)\n","do1 = keras.layers.Dropout(.3)(d1)\n","d2 = keras.layers.Dense(64, activation='relu')(do1)\n","output = keras.layers.Dense(5, activation='softmax')(d2)\n","\n","model = keras.models.Model(x_input, output)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['acc'])\n","model.summary()\n","\n","# pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n","# sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768]."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_13\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         [(None, 128)]             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 12,741\n","Trainable params: 12,741\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yqZ2BCV6lZ6d"},"source":["# 학습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"mgw-idFX5Y8k","executionInfo":{"status":"error","timestamp":1607059460761,"user_tz":-540,"elapsed":122226,"user":{"displayName":"포토네","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoVI2OB_qAlLntWqiZU54rUELhrL0YjmoQNBEmdQ=s64","userId":"07312452280450592829"}},"outputId":"278a8e3d-fd61-4711-c558-77b8f642ed6a"},"source":["es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","hist = model.fit(x_train, y_train, batch_size=64, epochs=40, validation_split=0.3, shuffle=True, verbose=1, callbacks=[es])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","601/601 [==============================] - 25s 42ms/step - loss: 1.0589 - acc: 0.5661 - val_loss: 0.7266 - val_acc: 0.7282\n","Epoch 2/40\n","601/601 [==============================] - 24s 41ms/step - loss: 0.5775 - acc: 0.7877 - val_loss: 0.6723 - val_acc: 0.7480\n","Epoch 3/40\n","601/601 [==============================] - 25s 41ms/step - loss: 0.3838 - acc: 0.8589 - val_loss: 0.7322 - val_acc: 0.7566\n","Epoch 4/40\n","601/601 [==============================] - 25s 41ms/step - loss: 0.2802 - acc: 0.8984 - val_loss: 0.7695 - val_acc: 0.7544\n","Epoch 5/40\n","568/601 [===========================>..] - ETA: 1s - loss: 0.2101 - acc: 0.9231"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-3f91ee47a6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"JnLHHQPv5cAW"},"source":["train_df = pd.read_csv('test_x.csv')\n","train_df['text'] = train_df['text'].str.lower().apply(alpha_num).apply(tokenize)\n","\n","sequences = tokenizer.texts_to_sequences(train_df['text'])\n","x_test = pad_sequences(sequences, maxlen=max_len)\n","\n","res = model.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EzNM1vD5d0A"},"source":["sample_submission = pd.read_csv('sample_submission.csv', encoding='utf-8')\n","sample_submission[['0', '1', '2', '3', '4']] = res\n","sample_submission.to_csv('writer_submission.csv', index = False, encoding = 'utf-8')"],"execution_count":null,"outputs":[]}]}